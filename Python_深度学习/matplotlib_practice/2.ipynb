{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-22T14:32:58.263026Z",
     "start_time": "2025-10-22T14:32:55.707028Z"
    }
   },
   "source": [
    "import torch\n",
    "X1 = torch.rand(10000,1) # 输入特征 1\n",
    "X2 = torch.rand(10000,1) # 输入特征 2\n",
    "X3 = torch.rand(10000,1) # 输入特征 3\n",
    "Y1 = ( (X1+X2+X3)<1 ).float() # 输出特征 1\n",
    "Y2 = ( (1<(X1+X2+X3)) & ((X1+X2+X3)<2) ).float() # 输出特征 2\n",
    "Y3 = ( (X1+X2+X3)>2 ).float() # 输出特征 3\n",
    "Data = torch.cat([X1,X2,X3,Y1,Y2,Y3],axis=1) # 整合数据集\n",
    "Data = Data.to('cuda:0') # 把数据集搬到 GPU 上\n",
    "Data.shape"
   ],
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m Y3 = ( (X1+X2+X3)>\u001B[32m2\u001B[39m ).float() \u001B[38;5;66;03m# 输出特征 3\u001B[39;00m\n\u001B[32m      8\u001B[39m Data = torch.cat([X1,X2,X3,Y1,Y2,Y3],axis=\u001B[32m1\u001B[39m) \u001B[38;5;66;03m# 整合数据集\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m Data = \u001B[43mData\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcuda:0\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 把数据集搬到 GPU 上\u001B[39;00m\n\u001B[32m     10\u001B[39m Data.shape\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001B[39m, in \u001B[36m_lazy_init\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    398\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    399\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    400\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmultiprocessing, you must use the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mspawn\u001B[39m\u001B[33m'\u001B[39m\u001B[33m start method\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    401\u001B[39m     )\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch._C, \u001B[33m\"\u001B[39m\u001B[33m_cuda_getDeviceCount\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mTorch not compiled with CUDA enabled\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    404\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    405\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[32m    406\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    407\u001B[39m     )\n",
      "\u001B[31mAssertionError\u001B[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
